{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590 - Advanced Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop: Baby You Can Drive My Car\n",
    "Train an agent to drive on highways. Uses the highway-env environment (https://github.com/eleurent/highway-env)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Highway](highway.gif)\n",
    "\n",
    "There are five **actions** in this environment:\n",
    "- change lane left (0)\n",
    "- none (1)\n",
    "- change lane right (2)\n",
    "- faster (3)\n",
    "- slower (4)\n",
    "\n",
    "**Reward** is awarded after each frame as a combination of velocity and colisions:\n",
    "\n",
    "$$R(s,a) = a\\frac{v - v_\\min}{v_\\max - v_\\min} - b\\,\\text{collision}$$\n",
    " \n",
    "where $v,\\,v_\\min,\\,v_\\max$ are the current, minimum and maximum speed of the ego-vehicle respectively, and $a,\\,b$ are coefficients (https://github.com/Farama-Foundation/HighwayEnv?tab=readme-ov-file).\n",
    "\n",
    "And the **state** represnetation gives kinematic infromation on the agents car and neighbouring cars.  \n",
    "\n",
    "![](highway_obs.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using Google colab you need to install packages  - comment out lines below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.820459Z",
     "start_time": "2025-04-01T19:07:50.817760Z"
    }
   },
   "source": [
    "#!apt install swig cmake ffmpeg\n",
    "#!apt-get install -y xvfb x11-utils\n",
    "#!pip install stable-baselines3[extra] pyglet\n",
    "#!pip install pyvirtualdisplay PyOpenGL PyOpenGL-accelerate\n",
    "#!pip install highway_env"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Google colab comment out this cell to make a virtual rendering canvas so render calls work (we still wont; see display!)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.835224Z",
     "start_time": "2025-04-01T19:07:50.833696Z"
    }
   },
   "source": [
    "#import pyvirtualdisplay\n",
    "#\n",
    "#_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
    "#                                    size=(1400, 900))\n",
    "#_ = _display.start()"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the highway environment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.841003Z",
     "start_time": "2025-04-01T19:07:50.839425Z"
    }
   },
   "source": "# !pip install highway_env",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.847368Z",
     "start_time": "2025-04-01T19:07:50.845803Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "import stable_baselines3 as sb3\n",
    "import highway_env"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the **highway-fast-v0** environment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.859692Z",
     "start_time": "2025-04-01T19:07:50.851586Z"
    }
   },
   "source": "env_eval = gym.make(\"highway-fast-v0\")",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:42: UserWarning: \u001B[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (5, 5)\u001B[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the environment action sapce and observation space"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.869499Z",
     "start_time": "2025-04-01T19:07:50.867637Z"
    }
   },
   "source": "env_eval.action_space",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.885257Z",
     "start_time": "2025-04-01T19:07:50.883097Z"
    }
   },
   "source": "env_eval.observation_space",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-inf, inf, (5, 5), float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the environment configuration."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.902629Z",
     "start_time": "2025-04-01T19:07:50.900516Z"
    }
   },
   "source": [
    "env_eval.unwrapped.config"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation': {'type': 'Kinematics'},\n",
       " 'action': {'type': 'DiscreteMetaAction'},\n",
       " 'simulation_frequency': 5,\n",
       " 'policy_frequency': 1,\n",
       " 'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle',\n",
       " 'screen_width': 600,\n",
       " 'screen_height': 150,\n",
       " 'centering_position': [0.3, 0.5],\n",
       " 'scaling': 5.5,\n",
       " 'show_trajectories': False,\n",
       " 'render_agent': True,\n",
       " 'offscreen_rendering': False,\n",
       " 'manual_control': False,\n",
       " 'real_time_rendering': False,\n",
       " 'lanes_count': 3,\n",
       " 'vehicles_count': 20,\n",
       " 'controlled_vehicles': 1,\n",
       " 'initial_lane_id': None,\n",
       " 'duration': 30,\n",
       " 'ego_spacing': 1.5,\n",
       " 'vehicles_density': 1,\n",
       " 'collision_reward': -1,\n",
       " 'right_lane_reward': 0.1,\n",
       " 'high_speed_reward': 0.4,\n",
       " 'lane_change_reward': 0,\n",
       " 'reward_speed_range': [20, 30],\n",
       " 'normalize_reward': True,\n",
       " 'offroad_terminal': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play an episode of the environment using random actions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.964708Z",
     "start_time": "2025-04-01T19:07:50.917315Z"
    }
   },
   "source": [
    "obs, info = env_eval.reset()\n",
    "terminate = False\n",
    "truncate = False\n",
    "while not (terminate or truncate):\n",
    "    action = env_eval.action_space.sample()\n",
    "    obs, reward, terminate, truncate, info = env_eval.step(action)\n",
    "    env_eval.render()\n",
    "env_eval.close()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete an episode of the environment using random actions recording actions and reward."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.988639Z",
     "start_time": "2025-04-01T19:07:50.968642Z"
    }
   },
   "source": [
    "cumulative_reward = 0\n",
    "actions = []\n",
    "action_map = {0: 'left', \n",
    "              1: 'none',\n",
    "              2: 'right',\n",
    "              3: 'faster',\n",
    "              4: 'slower'}\n",
    "\n",
    "terminate = False\n",
    "truncate = False\n",
    "while not (terminate or truncate):\n",
    "    action = env_eval.action_space.sample()\n",
    "    actions.append(action)\n",
    "    obs, reward, terminate, truncate, info = env_eval.step(action)\n",
    "    cumulative_reward += reward\n",
    "env_eval.close()"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:50.993550Z",
     "start_time": "2025-04-01T19:07:50.992070Z"
    }
   },
   "source": [
    "\n",
    "    \n",
    "print(\"Actions: \", ', '.join([action_map[a] for a in actions]))\n",
    "print(\"Cumulative Reward: {}\".format(cumulative_reward))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions:  right\n",
      "Cumulative Reward: 0.06666666666666665\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Train an Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DQN agent using stable-baselines3. In the highway environment episodes are typically note very long (typically < 30 timestpes). Therefore it makes sense to change some hyperparameters to reflect these shorter episodes. We suggest:\n",
    "\n",
    "- learning_rate = 0.0005\n",
    "- buffer_size = 15000\n",
    "- learning_starts = 200\n",
    "- gamma = 0.8\n",
    "- train_freq = 1\n",
    "- target_update_interval = 50\n",
    "- exploration_fraction=0.7\n",
    "\n",
    "Also the observation vector is reaonably large so a bigger value function network might work well:\n",
    "- 'net_arch':[256, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an environment without rendering. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:51.628742Z",
     "start_time": "2025-04-01T19:07:50.999983Z"
    }
   },
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "env_train = gym.make(\"highway-fast-v0\", render_mode=\"human\")\n",
    "env_train = Monitor(env_train)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:42: UserWarning: \u001B[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (5, 5)\u001B[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:07:51.637828Z",
     "start_time": "2025-04-01T19:07:51.633646Z"
    }
   },
   "source": [
    "tb_log = './log_tb_highway_DQN/'\n",
    "agent = sb3.DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env_train,\n",
    "    learning_rate=0.0005,\n",
    "    buffer_size=15000,\n",
    "    learning_starts=200,\n",
    "    gamma=0.8,\n",
    "    train_freq=1,\n",
    "    target_update_interval=50,\n",
    "    exploration_fraction=0.7,\n",
    "    policy_kwargs=dict(net_arch=[256, 128]),\n",
    "    verbose = 1,\n",
    "    tensorboard_log = tb_log\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the agent for a large number of steps."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-04-01T19:08:18.723522Z",
     "start_time": "2025-04-01T19:07:51.659171Z"
    }
   },
   "source": [
    "agent.learn(total_timesteps=1000)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./log_tb_highway_DQN/DQN_5\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 71       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 9.43     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 104      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 9.42     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 155      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 9.81     |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 213      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 12       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 274      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0913   |\n",
      "|    n_updates        | 73       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 9.55     |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 305      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 104      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.3     |\n",
      "|    ep_rew_mean      | 9.4      |\n",
      "|    exploration_rate | 0.532    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 345      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0455   |\n",
      "|    n_updates        | 144      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.1     |\n",
      "|    ep_rew_mean      | 9.33     |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 387      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00697  |\n",
      "|    n_updates        | 186      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | 8.67     |\n",
      "|    exploration_rate | 0.449    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 406      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.208    |\n",
      "|    n_updates        | 205      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 8.24     |\n",
      "|    exploration_rate | 0.418    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 429      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 228      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 7.73     |\n",
      "|    exploration_rate | 0.397    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 444      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 243      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 7.75     |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 482      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.245    |\n",
      "|    n_updates        | 281      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 7.85     |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 526      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.406    |\n",
      "|    n_updates        | 325      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.84     |\n",
      "|    ep_rew_mean      | 7.65     |\n",
      "|    exploration_rate | 0.252    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 551      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 350      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.55     |\n",
      "|    ep_rew_mean      | 7.42     |\n",
      "|    exploration_rate | 0.222    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 573      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 372      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.44     |\n",
      "|    ep_rew_mean      | 7.36     |\n",
      "|    exploration_rate | 0.18     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 604      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.496    |\n",
      "|    n_updates        | 403      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.59     |\n",
      "|    ep_rew_mean      | 7.52     |\n",
      "|    exploration_rate | 0.115    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 652      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.258    |\n",
      "|    n_updates        | 451      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.44     |\n",
      "|    ep_rew_mean      | 7.41     |\n",
      "|    exploration_rate | 0.0771   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 680      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.356    |\n",
      "|    n_updates        | 479      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.58     |\n",
      "|    ep_rew_mean      | 7.53     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 728      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 527      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.76     |\n",
      "|    ep_rew_mean      | 7.67     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 781      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.442    |\n",
      "|    n_updates        | 580      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.79     |\n",
      "|    ep_rew_mean      | 7.69     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 822      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.659    |\n",
      "|    n_updates        | 621      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 7.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 881      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 680      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 8.23     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 962      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.194    |\n",
      "|    n_updates        | 761      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x3158b67e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the tensorboard log using **TensorBoard** from the command line to view training progress: \n",
    "\n",
    "`tensorboard --logdir ./log_tb_highway_DQN/`\n",
    "\n",
    "Then open TensorBoard in a browser, typically located at:\n",
    "\n",
    "`http://localhost:6006/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the agent in the environment for 10 stepes including rendering."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:08:21.315375Z",
     "start_time": "2025-04-01T19:08:18.740566Z"
    }
   },
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(agent, env_eval, n_eval_episodes=10, render=False)\n",
    "print(\"Mean Reward: {} +/- {}\".format(mean_reward, std_reward))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward: 16.45774464905262 +/- 6.1674904953879155\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save an agent easily in SB3."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:08:21.330881Z",
     "start_time": "2025-04-01T19:08:21.326292Z"
    }
   },
   "source": [
    "agent.save(\"dqn_highway_agent\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily load an agent. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:08:21.346514Z",
     "start_time": "2025-04-01T19:08:21.341855Z"
    }
   },
   "source": "agent = sb3.dqn.DQN.load(\"dqn_highway_agent\")",
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the agent into the environment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:08:21.519999Z",
     "start_time": "2025-04-01T19:08:21.350852Z"
    }
   },
   "source": [
    "obs, _ = env_eval.reset()\n",
    "\n",
    "terminate = False\n",
    "truncate = False\n",
    "while not (terminate or truncate):\n",
    "\n",
    "    action, _ = agent.predict(obs)\n",
    "    obs, reward, terminate, truncate, info = env_eval.step(action)\n",
    "\n",
    "    env_eval.render()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:292: UserWarning: \u001B[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\u001B[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now continue training the agent."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:08:34.459144Z",
     "start_time": "2025-04-01T19:08:21.528733Z"
    }
   },
   "source": [
    "agent.set_env(env_eval)\n",
    "agent.learn(total_timesteps=1000)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./log_tb_highway_DQN/DQN_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.25     |\n",
      "|    ep_rew_mean      | 5.73     |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 75       |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 29       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.12     |\n",
      "|    ep_rew_mean      | 5.55     |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 57       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.25     |\n",
      "|    ep_rew_mean      | 6.94     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 80       |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 111      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.81     |\n",
      "|    ep_rew_mean      | 7.56     |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 81       |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 157      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 7.8      |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 81       |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 206      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.476    |\n",
      "|    n_updates        | 805      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.6     |\n",
      "|    ep_rew_mean      | 8.92     |\n",
      "|    exploration_rate | 0.621    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 79       |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 279      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.313    |\n",
      "|    n_updates        | 878      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12       |\n",
      "|    ep_rew_mean      | 9.17     |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 78       |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 335      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 934      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.6     |\n",
      "|    ep_rew_mean      | 8.89     |\n",
      "|    exploration_rate | 0.495    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 78       |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 372      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 971      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.8     |\n",
      "|    ep_rew_mean      | 9.02     |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 423      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.419    |\n",
      "|    n_updates        | 1022     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 9.54     |\n",
      "|    exploration_rate | 0.324    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 498      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0919   |\n",
      "|    n_updates        | 1097     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.3     |\n",
      "|    ep_rew_mean      | 9.46     |\n",
      "|    exploration_rate | 0.266    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 541      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.59     |\n",
      "|    n_updates        | 1140     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 9.56     |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 599      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.202    |\n",
      "|    n_updates        | 1198     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.0636   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 690      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 1289     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 10.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 773      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 1372     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 837      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.288    |\n",
      "|    n_updates        | 1436     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 897      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 1496     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 10.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 939      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 1538     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 980      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 1579     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x3229e3ce0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the agent after retraining."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:08:37.772032Z",
     "start_time": "2025-04-01T19:08:34.472351Z"
    }
   },
   "source": [
    "mean_reward, std_reward = evaluate_policy(agent, env_eval, n_eval_episodes=10, render=False)\n",
    "print(\"Mean Reward after retraining: {} +/- {}\".format(mean_reward, std_reward))\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n",
      "/opt/anaconda3/envs/AI/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward after retraining: 20.596696168929338 +/- 3.2557385203257265\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:08:37.778010Z",
     "start_time": "2025-04-01T19:08:37.776427Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
