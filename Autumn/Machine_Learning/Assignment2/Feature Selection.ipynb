{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Feature Selection\n",
    "\n",
    "Student ID: 24292215\n",
    "\n",
    "Student Name: Lucas Sipos George\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "The objective is to compare the performance of _Decision Trees_ and _Logistic Regression_ models on the `Student_Perf.csv` dataset. Both models inherently select features: decision trees through their branching process and logistic regression using L1 regularization. The goal is to assess which model performs better on this specific dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## Task 1: Accuracy\n",
    "For task 1, we will compare the performance of decision trees and logistic regression models on `Student_Perf.csv` dataset. This includes assessing their baseline accuracy, tuning hyperparameters (_max depth_ for decision trees, _L1 regularization_ for logistic regression) to improve performance, and visualizing the results in a chart."
   ],
   "id": "8699c181b8cb0cb3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:49.947310Z",
     "start_time": "2024-11-22T00:08:49.944346Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 269
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:49.987378Z",
     "start_time": "2024-11-22T00:08:49.977403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_student = pd.read_csv(\"Student_Perf.csv\", index_col=0)\n",
    "df_student.sort_index(inplace=True)\n",
    "df_student.head()"
   ],
   "id": "87c0e7021ebbc722",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   school  sex  age  address  famsize  Pstatus  Medu  Fedu  reason  guardian  \\\n",
       "0     0.0  0.0   18      1.0      0.0      0.0   4.0   4.0     0.0       1.0   \n",
       "1     0.0  0.0   17      1.0      0.0      1.0   1.0   1.0     0.0       0.0   \n",
       "2     0.0  0.0   15      1.0      1.0      1.0   1.0   1.0     2.0       1.0   \n",
       "3     0.0  0.0   15      1.0      0.0      1.0   4.0   2.0     1.0       1.0   \n",
       "4     0.0  0.0   16      1.0      0.0      1.0   3.0   3.0     1.0       0.0   \n",
       "\n",
       "   ...  internet  romantic  famrel  freetime  goout  Dalc  Walc  health  \\\n",
       "0  ...       0.0       0.0     3.0       2.0    3.0   0.0   0.0     2.0   \n",
       "1  ...       1.0       0.0     4.0       2.0    2.0   0.0   0.0     2.0   \n",
       "2  ...       1.0       0.0     3.0       2.0    1.0   1.0   2.0     2.0   \n",
       "3  ...       1.0       1.0     2.0       1.0    1.0   0.0   0.0     4.0   \n",
       "4  ...       0.0       0.0     3.0       2.0    1.0   0.0   1.0     4.0   \n",
       "\n",
       "   absences  outcome  \n",
       "0       4.0      Low  \n",
       "1       2.0      Low  \n",
       "2       6.0      Low  \n",
       "3       0.0     High  \n",
       "4       0.0     High  \n",
       "\n",
       "[5 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 270
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:50.019697Z",
     "start_time": "2024-11-22T00:08:50.017474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = df_student.shape\n",
    "low, high = df_student[\"outcome\"].value_counts().items()\n",
    "print(f\"Samples: {n[0]} rows and {n[1]} columns\")\n",
    "print(f\"Majority: {low[0]} = {low[1]} ({low[1] / n[0] * 100:.1f}%)\")\n",
    "print(f\"Minority: {high[0]} = {high[1]} ({high[1] / n[0] * 100:.1f}%)\")"
   ],
   "id": "db62c3e1313b8b2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 649 rows and 29 columns\n",
      "Majority: Low = 373 (57.5%)\n",
      "Minority: High = 276 (42.5%)\n"
     ]
    }
   ],
   "execution_count": 271
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that the majority class is `outcome` feature being _Low_ and minority being _High_.",
   "id": "488309433ffa34d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Baseline Generalisation Accuracy",
   "id": "d5280a89c4faae19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:50.089480Z",
     "start_time": "2024-11-22T00:08:50.087340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualisation_classifiers(_x_train, _x_test, _y_train, _y_test, _classifiers, positions):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy over for _classifiers over a number \n",
    "    of splits done on the dataset using hold-out testing.\n",
    "    \n",
    "    :param _x_train: list(), list of X training data\n",
    "    :param _x_test: list(), list of X testing data\n",
    "    :param _y_train: list(), list of y training data\n",
    "    :param _y_test: list(), list of y testing data\n",
    "    :param _classifiers: list(), list of classifiers\n",
    "    :param positions: list(), position for \"accuracies\" variable\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for i, classifier in enumerate(_classifiers):\n",
    "        confusions, scores = [], []\n",
    "        for j in range(SPLITS):\n",
    "            trained_classifier = classifier.fit(_x_train[j], _y_train[j])\n",
    "            y_dash = trained_classifier.predict(_x_test[j])\n",
    "\n",
    "            confusions.append(confusion_matrix(_y_test[j], y_dash))\n",
    "            scores.append(accuracy_score(_y_test[j], y_dash))\n",
    "        # for every classifier put the accuracy on the right position\n",
    "        accuracies[positions[i]] = np.mean(scores)\n",
    "        print(classifier)\n",
    "        print(f\"{SPLITS}x Accuracy: {accuracies[positions[i]]:.3f}\")\n",
    "        print(f\"Confusion Matrix:\\n{np.sum(confusions, axis=0)}\", end=\"\\n\\n\")"
   ],
   "id": "39f3f49325ee7184",
   "outputs": [],
   "execution_count": 272
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:50.130129Z",
     "start_time": "2024-11-22T00:08:50.128208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "# max_iter = 1000 because with the default value throws error\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "classifiers = [dt, lr]\n",
    "# list of accuracies for baseline and regularised models\n",
    "accuracies = [0] * 4"
   ],
   "id": "6a4da5c7200d7dc",
   "outputs": [],
   "execution_count": 273
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:50.189442Z",
     "start_time": "2024-11-22T00:08:50.187641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = df_student.pop(\"outcome\").values\n",
    "X = df_student.values"
   ],
   "id": "2b38f03e83d55266",
   "outputs": [],
   "execution_count": 274
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:51.057778Z",
     "start_time": "2024-11-22T00:08:50.214556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# number of splits to train and test on\n",
    "SPLITS = 25\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "for i in range(SPLITS):\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(X, y, test_size=1 / 3, random_state=i)\n",
    "    X_train.append(_X_train)\n",
    "    X_test.append(_X_test)\n",
    "    y_train.append(_y_train)\n",
    "    y_test.append(_y_test)\n",
    "visualisation_classifiers(X_train, X_test, y_train, y_test, classifiers, [0, 2])"
   ],
   "id": "eed3db6743dfd0bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "25x Accuracy: 0.635\n",
      "Confusion Matrix:\n",
      "[[1350  996]\n",
      " [ 986 2093]]\n",
      "\n",
      "LogisticRegression(max_iter=1000)\n",
      "25x Accuracy: 0.712\n",
      "Confusion Matrix:\n",
      "[[1618  728]\n",
      " [ 832 2247]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 275
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see the `Logistic Regression` is doing better than `Decision Tree`.",
   "id": "40f35674e7237907"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Grid Search for Decision Tree\n",
    "\n",
    "We will try to find an optimal value for the `min_sample_leaf` parameter."
   ],
   "id": "f9b22d840c747330"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:51.955468Z",
     "start_time": "2024-11-22T00:08:51.129905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\"min_samples_leaf\": [1, 3, 5, 10, 15, 20, 25, 30, 40, 50, 75, 100]}\n",
    "\n",
    "# grid search with respect to accuracy\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=6, n_jobs=-1, scoring=\"accuracy\")\n",
    "grid_search = grid_search.fit(X_train[0], y_train[0])\n",
    "scores_df = pd.DataFrame(grid_search.cv_results_)\n",
    "# sort by their scores\n",
    "scores_df = scores_df.sort_values(by=[\"rank_test_score\"]).reset_index(drop=\"index\")\n",
    "# print only the values needed\n",
    "scores_df[[\"mean_test_score\", \"param_min_samples_leaf\"]]"
   ],
   "id": "2e29e75938f8c600",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    mean_test_score  param_min_samples_leaf\n",
       "0          0.680556                      10\n",
       "1          0.678241                      15\n",
       "2          0.673611                      20\n",
       "3          0.671296                      75\n",
       "4          0.668981                      30\n",
       "5          0.657407                      40\n",
       "6          0.657407                       5\n",
       "7          0.655093                       3\n",
       "8          0.655093                     100\n",
       "9          0.652778                      25\n",
       "10         0.650463                      50\n",
       "11         0.643519                       1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680556</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.678241</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.673611</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.671296</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.668981</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.657407</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.657407</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.655093</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.655093</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.652778</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.650463</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.643519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 276
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "From the table above we get that **10** is the best parameter values for `min_samples_leaf`, but we want to see if there are any better. Below we try again, but for all the values around **10** inclusively. ",
   "id": "83fc96e1b4bfe7a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:52.000461Z",
     "start_time": "2024-11-22T00:08:51.970038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# integer parameters in [6,15)\n",
    "param_grid = {\"min_samples_leaf\": np.arange(6, 15)}\n",
    "\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=6, n_jobs=-1, scoring=\"accuracy\")\n",
    "grid_search = grid_search.fit(X_train[0], y_train[0])\n",
    "scores_df = pd.DataFrame(grid_search.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=[\"rank_test_score\"]).reset_index(drop=\"index\")\n",
    "scores_df[[\"mean_test_score\", \"param_min_samples_leaf\"]]"
   ],
   "id": "9514e56c699e526b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mean_test_score  param_min_samples_leaf\n",
       "0         0.699074                      13\n",
       "1         0.692130                      14\n",
       "2         0.682870                      10\n",
       "3         0.680556                       9\n",
       "4         0.675926                      12\n",
       "5         0.673611                       7\n",
       "6         0.664352                       8\n",
       "7         0.662037                      11\n",
       "8         0.657407                       6"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.699074</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.692130</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682870</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680556</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.675926</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.673611</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.664352</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.662037</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.657407</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 277
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see there are better parameters than **10**, so we choose the best one, **13**, and test it on the `visualisation_classifiers`.",
   "id": "96f62723a1d572dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:52.064838Z",
     "start_time": "2024-11-22T00:08:52.026181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a Decision Tree with the best parameters from the grid search\n",
    "dt_new = DecisionTreeClassifier(**grid_search.best_params_)\n",
    "visualisation_classifiers(X_train, X_test, y_train, y_test, [dt_new], [1])"
   ],
   "id": "3909f51594066f62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(min_samples_leaf=13)\n",
      "25x Accuracy: 0.668\n",
      "Confusion Matrix:\n",
      "[[1432  914]\n",
      " [ 887 2192]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 278
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We've tested the Decision Tree created from the best parameters (`min_samples_leaf=13`), and we can see significant improvement in _accuracy_.",
   "id": "55880b2862b64ea4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Grid Search for Logistic Regression\n",
    "\n",
    "We will try to find an optimal value for the `C` parameter. We set `penalty` to `l1` because that's a problem requirement and `solver` to `liblinear` because the default value isn't compatible with `l1`."
   ],
   "id": "b2585d70bf24e2e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:54.548043Z",
     "start_time": "2024-11-22T00:08:52.101754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\"C\": [0.0001, 0.001, 0.01, 0.1, 1, 5, 10, 15, 20, 25, 30, 50, 75, 100, 1000, 10000],\n",
    "              \"penalty\": [\"l1\"],\n",
    "              \"solver\": [\"liblinear\"]}\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=6, scoring=\"accuracy\")\n",
    "grid_search = grid_search.fit(X_train[0], y_train[0])\n",
    "scores_df = pd.DataFrame(grid_search.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=[\"rank_test_score\"]).reset_index(drop=\"index\")\n",
    "scores_df[[\"mean_test_score\", \"param_C\"]]"
   ],
   "id": "c865b996c48481e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    mean_test_score     param_C\n",
       "0          0.708333     15.0000\n",
       "1          0.708333     25.0000\n",
       "2          0.708333     30.0000\n",
       "3          0.708333     50.0000\n",
       "4          0.708333  10000.0000\n",
       "5          0.706019     20.0000\n",
       "6          0.706019     75.0000\n",
       "7          0.706019    100.0000\n",
       "8          0.706019   1000.0000\n",
       "9          0.703704     10.0000\n",
       "10         0.701389      5.0000\n",
       "11         0.696759      0.1000\n",
       "12         0.694444      1.0000\n",
       "13         0.567130      0.0100\n",
       "14         0.428241      0.0001\n",
       "15         0.428241      0.0010"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.706019</td>\n",
       "      <td>20.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.706019</td>\n",
       "      <td>75.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.706019</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.706019</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.703704</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.701389</td>\n",
       "      <td>5.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.696759</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.694444</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.567130</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.428241</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.428241</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 279
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "From the table above we can see that a lot of values have the same _accuracy_. There should be no need in verifying further into the matter, but for the sake of showing this we will run the grid search with the closes values to **15**.",
   "id": "ff364c372df2a185"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:56.369501Z",
     "start_time": "2024-11-22T00:08:54.582125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\"C\": np.arange(11, 20),\n",
    "              \"penalty\": [\"l1\"],\n",
    "              \"solver\": [\"liblinear\"]}\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=6, scoring=\"accuracy\")\n",
    "grid_search = grid_search.fit(X_train[0], y_train[0])\n",
    "scores_df = pd.DataFrame(grid_search.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=[\"rank_test_score\"]).reset_index(drop=\"index\")\n",
    "scores_df[[\"mean_test_score\", \"param_C\"]]"
   ],
   "id": "c12909e68abf3983",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mean_test_score  param_C\n",
       "0         0.708333       15\n",
       "1         0.708333       16\n",
       "2         0.708333       17\n",
       "3         0.708333       18\n",
       "4         0.706019       13\n",
       "5         0.706019       14\n",
       "6         0.706019       19\n",
       "7         0.703704       11\n",
       "8         0.703704       12"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.706019</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.706019</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.706019</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.703704</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.703704</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 280
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As said before, there is no improvement in accuracy, but the grid search will take the lowest value, which is **14** now.",
   "id": "9cccd5d8941bb4ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:57.406949Z",
     "start_time": "2024-11-22T00:08:56.394146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr_new = LogisticRegression(**grid_search.best_params_)\n",
    "visualisation_classifiers(X_train, X_test, y_train, y_test, [lr_new], [3])"
   ],
   "id": "705f9a5c65db1c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=15, penalty='l1', solver='liblinear')\n",
      "25x Accuracy: 0.710\n",
      "Confusion Matrix:\n",
      "[[1644  702]\n",
      " [ 873 2206]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 281
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We've tested the Logistic Regression created from the best parameters (`C=14`), and we can see that it got a little worse than the default Logistic Regression.",
   "id": "f40b8f222e6f43d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Report on Accuracies",
   "id": "eb02940bd55c64ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:57.444862Z",
     "start_time": "2024-11-22T00:08:57.442819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# bind labels to values\n",
    "results = dict(zip([\"Tree Baseline\", \"Tree Reg\", \"Logistic Baseline\", \"Logistic Reg\"], accuracies))\n",
    "results"
   ],
   "id": "ab7b6dc45cdbdb0a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tree Baseline': 0.6346543778801843,\n",
       " 'Tree Reg': 0.6680184331797234,\n",
       " 'Logistic Baseline': 0.7124423963133643,\n",
       " 'Logistic Reg': 0.7096774193548387}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 282
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we can clearly see that `Tree Reg` is doing significantly better than `Tree Baseline`, and `Logistic Baseline` is doing a little better than `Logistic Reg`.",
   "id": "24a8cc3c0a65734c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:57.540159Z",
     "start_time": "2024-11-22T00:08:57.476565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(results.keys(), results.values(), color='skyblue')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Test Accuracy\")\n",
    "plt.legend([\"Test Accuracy\"])\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ],
   "id": "ee16f07cced2f98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 283
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Above we can see how all the _accuracies_ with respect to each technique. And again there is the clear representation of which one is doing better and which one is doing worse (the explanation is above).\n",
    "\n",
    "---"
   ],
   "id": "2fac34e98e72232e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 2: Feature Selection\n",
    "\n",
    "For task 2, we will analyze feature selection using regularized Decision Trees and Logistic Regression. We will compare selected features, evaluate the stability of selections across runs, and examine the agreement between the two models. This will provide insights into feature importance and model behavior. "
   ],
   "id": "d0b297ea481d806e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:57.596399Z",
     "start_time": "2024-11-22T00:08:57.591418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_features(features, num=True):\n",
    "    \"\"\"\n",
    "    Prints the features nicely.\n",
    "    \n",
    "    :param features: List[str, int|str], list of pairs, e.g.: 0 - feature, 1 - importance/coefficient | usage\n",
    "    :param num: bool, if the second value of the pairs is number `num` is True, otherwise False\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # if there are numbers, format with precision of 3\n",
    "    indent = \".3f\" if num else \"\"\n",
    "    _length = len(features)\n",
    "    # for odd numbers print the 'odd' one last\n",
    "    _offset = _length % 2\n",
    "    for index in range(_length // 2):\n",
    "        print(f\"{str(index + 1) + \".\":<4}{features[index][0]:<10} -> {features[index][1]:<10{indent}}\", end=\"\")\n",
    "        print(\n",
    "            f\"{str(index + 1 + _offset + _length // 2) + \".\":<4}{features[index + _offset + _length // 2][0]:<10} -> {features[index + _offset + _length // 2][1]:<10{indent}}\")\n",
    "    if _length % 2 == 1:\n",
    "        print(\n",
    "            f\"{str(_length // 2 + 1) + \".\":<4}{features[_length // 2][0]:<10} -> {features[_length // 2][1]:<10{indent}}\")\n",
    "    print()"
   ],
   "id": "5e105438cf381d67",
   "outputs": [],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:57.636528Z",
     "start_time": "2024-11-22T00:08:57.630088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dt_new.fit(X_train[0], y_train[0])\n",
    "\n",
    "# create a dataframe with feature and feature importance sorted by feature importance\n",
    "select_features_dt = pd.DataFrame({\n",
    "    \"Feature\": df_student.columns,\n",
    "    \"Importance\": dt_new.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Filter out features with zero importance\n",
    "selected_features_dt = select_features_dt[select_features_dt[\"Importance\"] > 0].values\n",
    "# Filter out features with positive importance\n",
    "not_selected_features_dt = select_features_dt[select_features_dt[\"Importance\"] <= 0].values\n",
    "print(f\"{len(selected_features_dt)} selected features (Decision Tree):\")\n",
    "print_features(selected_features_dt)\n",
    "print(f\"{len(not_selected_features_dt)} zero importance features (Decision Tree):\")\n",
    "print_features(not_selected_features_dt)"
   ],
   "id": "cbe7411c84e9bbe2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 selected features (Decision Tree):\n",
      "1.  failures   -> 0.234     8.  internet   -> 0.048     \n",
      "2.  Medu       -> 0.156     9.  sex        -> 0.028     \n",
      "3.  absences   -> 0.155     10. Walc       -> 0.019     \n",
      "4.  Dalc       -> 0.115     11. school     -> 0.018     \n",
      "5.  higher     -> 0.082     12. famsup     -> 0.011     \n",
      "6.  health     -> 0.071     13. studytime  -> 0.008     \n",
      "7.  famsize    -> 0.056     \n",
      "\n",
      "15 zero importance features (Decision Tree):\n",
      "1.  schoolsup  -> 0.000     9.  famrel     -> 0.000     \n",
      "2.  guardian   -> 0.000     10. freetime   -> 0.000     \n",
      "3.  paid       -> 0.000     11. goout      -> 0.000     \n",
      "4.  activities -> 0.000     12. Pstatus    -> 0.000     \n",
      "5.  nursery    -> 0.000     13. address    -> 0.000     \n",
      "6.  reason     -> 0.000     14. age        -> 0.000     \n",
      "7.  traveltime -> 0.000     15. Fedu       -> 0.000     \n",
      "8.  romantic   -> 0.000     \n",
      "\n"
     ]
    }
   ],
   "execution_count": 285
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we run the cell above multiple times we find out that the features selected by the Decision Tree classifier differ from run to run. The only number of features selected that I've got through the runs are **13** or **12**. I will talk more about it later on.",
   "id": "9c34d2df4bfbd2f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:08:57.721336Z",
     "start_time": "2024-11-22T00:08:57.661575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr_new.fit(X_train[0], y_train[0])\n",
    "\n",
    "# create a dataframe with feature and coefficient sorted by coefficient\n",
    "select_features_lr = pd.DataFrame({\n",
    "    \"Feature\": df_student.columns,\n",
    "    \"Coefficient\": lr_new.coef_[0]\n",
    "}).sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "# Filter out features with zero/negative coefficients\n",
    "selected_features_lr = select_features_lr[select_features_lr[\"Coefficient\"] > 0].values\n",
    "# Filter out features with positive coefficients\n",
    "not_selected_features_lr = select_features_lr[select_features_lr[\"Coefficient\"] <= 0].values\n",
    "print(f\"{len(selected_features_lr)} selected features (Logistic Regression):\")\n",
    "print_features(selected_features_lr)\n",
    "print(f\"{len(not_selected_features_lr)} zero/negative coefficient features (Logistic Regression):\")\n",
    "print_features(not_selected_features_lr)"
   ],
   "id": "e883a5bbc435fd85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 selected features (Logistic Regression):\n",
      "1.  failures   -> 1.583     8.  guardian   -> 0.300     \n",
      "2.  schoolsup  -> 0.934     9.  health     -> 0.219     \n",
      "3.  school     -> 0.508     10. famsup     -> 0.190     \n",
      "4.  Pstatus    -> 0.473     11. goout      -> 0.113     \n",
      "5.  Dalc       -> 0.442     12. absences   -> 0.076     \n",
      "6.  sex        -> 0.416     13. Fedu       -> 0.073     \n",
      "7.  famsize    -> 0.412     14. nursery    -> 0.032     \n",
      "\n",
      "14 zero/negative coefficient features (Logistic Regression):\n",
      "1.  Walc       -> -0.008    8.  studytime  -> -0.170    \n",
      "2.  reason     -> -0.012    9.  age        -> -0.204    \n",
      "3.  freetime   -> -0.027    10. famrel     -> -0.208    \n",
      "4.  romantic   -> -0.100    11. internet   -> -0.384    \n",
      "5.  traveltime -> -0.134    12. address    -> -0.502    \n",
      "6.  activities -> -0.142    13. Medu       -> -0.528    \n",
      "7.  paid       -> -0.166    14. higher     -> -2.823    \n",
      "\n"
     ]
    }
   ],
   "execution_count": 286
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, if we run the cell above, we can see that every time we run it we get the same values and the number of features selected by Logistic Regression is **14**. Something interesting that we can see here is that, compared to Decision Tree, we don't have 0 values, but we have negative ones, something that we don't see when using Decision Tree.",
   "id": "cbdfa7603eddf685"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:09:01.639179Z",
     "start_time": "2024-11-22T00:08:57.745050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# number of iterations\n",
    "ITERATIONS = 100\n",
    "# mapping of selected values for both, decision tree, logistic regression and overall\n",
    "mapping_values_selected, mapping_selected_b, mapping_selected_dt, mapping_selected_lr = {}, {}, {}, {}\n",
    "for i in range(ITERATIONS):\n",
    "    dt_new.fit(X_train[0], y_train[0])\n",
    "    lr_new.fit(X_train[0], y_train[0])\n",
    "\n",
    "    select_features_dt = pd.DataFrame({\n",
    "        \"Feature\": df_student.columns,\n",
    "        \"Importance\": dt_new.feature_importances_\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "    select_features_lr = pd.DataFrame({\n",
    "        \"Feature\": df_student.columns,\n",
    "        \"Coefficient\": lr_new.coef_[0]\n",
    "    }).sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "    selected_features_dt = select_features_dt[select_features_dt[\"Importance\"] > 0].values\n",
    "    selected_features_lr = select_features_lr[select_features_lr[\"Coefficient\"] > 0].values\n",
    "    \n",
    "    all_selected_features = list(set([x for x, y in selected_features_dt] + [x for x, y in selected_features_lr]))\n",
    "    c_both, c_dt, c_lr = 0, 0, 0\n",
    "    for i in range(len(all_selected_features)):\n",
    "        if all_selected_features[i] in selected_features_dt and all_selected_features[i] in selected_features_lr:\n",
    "            mapping_selected_b[all_selected_features[i]] = mapping_selected_b.get(all_selected_features[i], 0) + 1\n",
    "            all_selected_features[i] = (all_selected_features[i], \"Both\")\n",
    "            c_both += 1\n",
    "        elif all_selected_features[i] in selected_features_dt:\n",
    "            mapping_selected_dt[all_selected_features[i]] = mapping_selected_dt.get(all_selected_features[i], 0) + 1\n",
    "            all_selected_features[i] = (all_selected_features[i], \"DT\")\n",
    "            c_dt += 1\n",
    "        else:\n",
    "            mapping_selected_lr[all_selected_features[i]] = mapping_selected_lr.get(all_selected_features[i], 0) + 1\n",
    "            all_selected_features[i] = (all_selected_features[i], \"LR\")\n",
    "            c_lr += 1\n",
    "        mapping_values_selected[all_selected_features[i][0]] = (mapping_values_selected\n",
    "                                                                .get(all_selected_features[i][0], 0) + 1)\n",
    "    all_selected_features = sorted(all_selected_features, key=lambda x: x[1])\n",
    "    # TODO: if you uncomment these lines you can see details about everything at every iteration\n",
    "    # TODO: if you decide to uncomment change ITERATION variable to a lower one\n",
    "    # print(f\"Both -> {c_both:<5}Decision Tree -> {c_dt:<5} Logistic Regression -> {c_lr}\")\n",
    "    # print(\"Features selected by classifier:\")\n",
    "    # print_features(all_selected_features, False)\n",
    "print(f\"Frequency of all values selected over iterations ({ITERATIONS}):\")\n",
    "print_features(sorted(list(mapping_values_selected.items()), key=lambda x: x[0].lower()), False)\n",
    "print(f\"Frequency of 'Both' values selected over iterations ({ITERATIONS}):\")\n",
    "print_features(sorted(list(mapping_selected_b.items()), key=lambda x: x[0].lower()), False)\n",
    "print(f\"Frequency of 'DT' values selected over iterations ({ITERATIONS}):\")\n",
    "print_features(sorted(list(mapping_selected_dt.items()), key=lambda x: x[0].lower()), False)\n",
    "print(f\"Frequency of 'LR' values selected over iterations ({ITERATIONS}):\")\n",
    "print_features(sorted(list(mapping_selected_lr.items()), key=lambda x: x[0].lower()), False)"
   ],
   "id": "8b6da168991979d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of all values selected over iterations (100):\n",
      "1.  absences   -> 100       11. internet   -> 100       \n",
      "2.  Dalc       -> 100       12. Medu       -> 100       \n",
      "3.  failures   -> 100       13. nursery    -> 100       \n",
      "4.  famsize    -> 100       14. Pstatus    -> 100       \n",
      "5.  famsup     -> 100       15. school     -> 100       \n",
      "6.  Fedu       -> 100       16. schoolsup  -> 100       \n",
      "7.  goout      -> 100       17. sex        -> 100       \n",
      "8.  guardian   -> 100       18. studytime  -> 100       \n",
      "9.  health     -> 100       19. Walc       -> 100       \n",
      "10. higher     -> 100       \n",
      "\n",
      "Frequency of 'Both' values selected over iterations (100):\n",
      "1.  absences   -> 100       5.  famsup     -> 41        \n",
      "2.  Dalc       -> 100       6.  health     -> 100       \n",
      "3.  failures   -> 100       7.  school     -> 100       \n",
      "4.  famsize    -> 100       8.  sex        -> 100       \n",
      "\n",
      "Frequency of 'DT' values selected over iterations (100):\n",
      "1.  higher     -> 100       4.  studytime  -> 100       \n",
      "2.  internet   -> 100       5.  Walc       -> 100       \n",
      "3.  Medu       -> 100       \n",
      "\n",
      "Frequency of 'LR' values selected over iterations (100):\n",
      "1.  famsup     -> 59        5.  nursery    -> 100       \n",
      "2.  Fedu       -> 100       6.  Pstatus    -> 100       \n",
      "3.  goout      -> 100       7.  schoolsup  -> 100       \n",
      "4.  guardian   -> 100       \n",
      "\n"
     ]
    }
   ],
   "execution_count": 287
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If you uncomment the lines below `TODO` the first, number of iterations (`ITERATIONS`), lines show us the number of features that were chose by decision tree, logistic regression and both of them, and after that every feature selected and by whom.\n",
    "\n",
    "If you choose not to uncomment those lines we get 4 \"tables\" that represent the following, a frequency table of:\n",
    "1. all the features over all the iterations.\n",
    "2. the features selected by both Decision Tree and Logistic Regression over all iterations.\n",
    "3. the features selected by the Decision Tree over all iterations.\n",
    "4. the features selected by the Logistic Regression over all iterations.\n",
    "\n",
    "The first table tells us that every time we ran the `fit` function we got the same features selected.\n",
    "\n",
    "The second table shows us that one of the classifiers is not always taking the `famsup` feature. I won't say the value of `famsup` because it is inconsistent.\n",
    "\n",
    "The third table tells us that Decision Tree is the classifier that chooses `famsup` feature only sometimes, and if we look into the second table we find out how many times `famsup` feature was selected by Decision Tree.\n",
    "\n",
    "The forth table gives us about the same type of information as the previous one, respectively that Logistic Regression chooses `famsup` every interation, also interpreted as chooses `famsup` (value of `famsup` cannot be specified because it is inconsistent) times more than Decision Tree.\n",
    "\n",
    "We can see that the features chosen by classifiers are all consistent expect for `famsup` which is inconsistent for Decision Tree classifier. We can also see that the features selected by both are `Dalc, famsize, absences, school, sex, failures, famsup, health`. But they also have different features selected, which are a bit more for Logistic Regression (**6/7**) than for Decision Tree (**5**) such as:\n",
    "- for Decision Tree `internet, higher, studytime, Medu, Walc`\n",
    "- for Logistic Regression `Pstatus, schoolsup, Fedu, goout, nursery, guardian` and sometimes `famsup`\n"
   ],
   "id": "53489d04ebf229a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:09:01.703247Z",
     "start_time": "2024-11-22T00:09:01.701911Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "91224d35667cc4ee",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
