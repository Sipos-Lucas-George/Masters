{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T19:36:56.639089Z",
     "start_time": "2024-10-13T19:36:56.636353Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:36:56.650663Z",
     "start_time": "2024-10-13T19:36:56.647777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"common_topics\") as f:\n",
    "    texts = [line.strip() for line in f.readlines()]\n",
    "print(texts)"
   ],
   "id": "e46918ab0f064cb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cats are the most popular pets in the world', 'Cats have nine lives', 'Cats are very independent animals', 'Cats are excellent hunters', 'Cats are very clean animals', 'Cats can purr to show contentment', 'Cats can hiss to show aggression', 'Cats have a very strong sense of smell', 'Cats can see in the dark', 'Cats are very playful animals']\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:36:56.717209Z",
     "start_time": "2024-10-13T19:36:56.714515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ],
   "id": "c562bb250916ef42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wouldn', 'before', 'those', 'against', 'over', 'theirs', \"aren't\", \"won't\", 'needn', 'by', 'up', 'the', \"it's\", \"that'll\", 'didn', 'this', 'from', 'not', 'me', 'i', 'have', \"weren't\", 'now', 'under', 'shan', 'hers', \"you're\", 'how', \"hasn't\", 'any', 'had', 'while', 'both', 'that', 'so', \"couldn't\", 'should', 'been', 'why', 'its', 'yourself', 'out', 'only', 'an', \"don't\", 'hasn', 'shouldn', 'doesn', 'yours', 's', 'aren', 'him', 'very', 'couldn', 'down', \"needn't\", 'she', 'into', 'himself', 'herself', 'isn', 'hadn', 'here', 'doing', 'such', 'no', \"wouldn't\", 'most', \"isn't\", \"didn't\", \"wasn't\", 'a', 'you', 'being', 'he', \"she's\", 'or', 'did', 'don', 'has', 'his', 'there', 'nor', 'whom', 'just', 'as', 'then', 'and', 'through', 'haven', \"hadn't\", 'be', 'each', 'can', 'them', \"you'll\", 'off', 'they', 'my', 'weren', 'of', 'was', 'having', 't', 'on', 'will', 'o', 've', 'than', 'our', \"haven't\", 'are', 'y', 'during', \"doesn't\", 'in', 'mustn', 'some', 'myself', 'm', 'ours', 'own', 'do', 'her', 'who', 'once', 'd', 'to', 're', 'with', 'same', 'ain', 'more', 'll', 'wasn', \"you'd\", 'yourselves', 'these', 'for', 'after', 'between', 'ma', 'at', 'too', 'does', \"you've\", 'when', 'your', 'which', \"should've\", 'few', 'were', 'other', 'won', 'below', \"mustn't\", 'is', \"mightn't\", \"shouldn't\", 'their', 'until', 'where', 'mightn', 'about', 'all', 'ourselves', \"shan't\", 'we', 'it', 'because', 'am', 'above', 'themselves', 'if', 'but', 'itself', 'again', 'further', 'what'}\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:36:56.787099Z",
     "start_time": "2024-10-13T19:36:56.785217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "words_list = []\n",
    "for text_item in texts:\n",
    "    words = text_item.split()\n",
    "    r_words = [word for word in words if word not in stop_words]\n",
    "    words_list.append(r_words)"
   ],
   "id": "30aa6b68e5bb9b72",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:36:56.804215Z",
     "start_time": "2024-10-13T19:36:56.801949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_tf(text):\n",
    "    word_counts = {}\n",
    "    total_words = len(text)\n",
    "    for word in text:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "    tf_scores = {word: count / total_words for word, count in word_counts.items()}\n",
    "    return tf_scores\n",
    "\n",
    "\n",
    "tf_scores_list = [calculate_tf(text) for text in words_list]\n",
    "print(tf_scores_list)"
   ],
   "id": "e09af72f5934af4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Cats': 0.25, 'popular': 0.25, 'pets': 0.25, 'world': 0.25}, {'Cats': 0.3333333333333333, 'nine': 0.3333333333333333, 'lives': 0.3333333333333333}, {'Cats': 0.3333333333333333, 'independent': 0.3333333333333333, 'animals': 0.3333333333333333}, {'Cats': 0.3333333333333333, 'excellent': 0.3333333333333333, 'hunters': 0.3333333333333333}, {'Cats': 0.3333333333333333, 'clean': 0.3333333333333333, 'animals': 0.3333333333333333}, {'Cats': 0.25, 'purr': 0.25, 'show': 0.25, 'contentment': 0.25}, {'Cats': 0.25, 'hiss': 0.25, 'show': 0.25, 'aggression': 0.25}, {'Cats': 0.25, 'strong': 0.25, 'sense': 0.25, 'smell': 0.25}, {'Cats': 0.3333333333333333, 'see': 0.3333333333333333, 'dark': 0.3333333333333333}, {'Cats': 0.3333333333333333, 'playful': 0.3333333333333333, 'animals': 0.3333333333333333}]\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:36:56.854759Z",
     "start_time": "2024-10-13T19:36:56.849025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "tf_matrix = pd.DataFrame(tf_scores_list).fillna(0)\n",
    "tf_matrix.to_csv(\"tf_scores.csv\")\n",
    "print(tf_matrix)"
   ],
   "id": "c4d15e0aecdba3df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Cats  popular  pets  world      nine     lives  independent   animals  \\\n",
      "0  0.250000     0.25  0.25   0.25  0.000000  0.000000     0.000000  0.000000   \n",
      "1  0.333333     0.00  0.00   0.00  0.333333  0.333333     0.000000  0.000000   \n",
      "2  0.333333     0.00  0.00   0.00  0.000000  0.000000     0.333333  0.333333   \n",
      "3  0.333333     0.00  0.00   0.00  0.000000  0.000000     0.000000  0.000000   \n",
      "4  0.333333     0.00  0.00   0.00  0.000000  0.000000     0.000000  0.333333   \n",
      "5  0.250000     0.00  0.00   0.00  0.000000  0.000000     0.000000  0.000000   \n",
      "6  0.250000     0.00  0.00   0.00  0.000000  0.000000     0.000000  0.000000   \n",
      "7  0.250000     0.00  0.00   0.00  0.000000  0.000000     0.000000  0.000000   \n",
      "8  0.333333     0.00  0.00   0.00  0.000000  0.000000     0.000000  0.000000   \n",
      "9  0.333333     0.00  0.00   0.00  0.000000  0.000000     0.000000  0.333333   \n",
      "\n",
      "   excellent   hunters  ...  show  contentment  hiss  aggression  strong  \\\n",
      "0   0.000000  0.000000  ...  0.00         0.00  0.00        0.00    0.00   \n",
      "1   0.000000  0.000000  ...  0.00         0.00  0.00        0.00    0.00   \n",
      "2   0.000000  0.000000  ...  0.00         0.00  0.00        0.00    0.00   \n",
      "3   0.333333  0.333333  ...  0.00         0.00  0.00        0.00    0.00   \n",
      "4   0.000000  0.000000  ...  0.00         0.00  0.00        0.00    0.00   \n",
      "5   0.000000  0.000000  ...  0.25         0.25  0.00        0.00    0.00   \n",
      "6   0.000000  0.000000  ...  0.25         0.00  0.25        0.25    0.00   \n",
      "7   0.000000  0.000000  ...  0.00         0.00  0.00        0.00    0.25   \n",
      "8   0.000000  0.000000  ...  0.00         0.00  0.00        0.00    0.00   \n",
      "9   0.000000  0.000000  ...  0.00         0.00  0.00        0.00    0.00   \n",
      "\n",
      "   sense  smell       see      dark   playful  \n",
      "0   0.00   0.00  0.000000  0.000000  0.000000  \n",
      "1   0.00   0.00  0.000000  0.000000  0.000000  \n",
      "2   0.00   0.00  0.000000  0.000000  0.000000  \n",
      "3   0.00   0.00  0.000000  0.000000  0.000000  \n",
      "4   0.00   0.00  0.000000  0.000000  0.000000  \n",
      "5   0.00   0.00  0.000000  0.000000  0.000000  \n",
      "6   0.00   0.00  0.000000  0.000000  0.000000  \n",
      "7   0.25   0.25  0.000000  0.000000  0.000000  \n",
      "8   0.00   0.00  0.333333  0.333333  0.000000  \n",
      "9   0.00   0.00  0.000000  0.000000  0.333333  \n",
      "\n",
      "[10 rows x 22 columns]\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:36:56.871171Z",
     "start_time": "2024-10-13T19:36:56.865142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "filtered_text = [\" \".join(lst) for lst in words_list]\n",
    "X = vectorizer.fit_transform(filtered_text)\n",
    "tfidf_scores = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_scores.to_csv(\"tfidf_scores.csv\")\n",
    "print(tfidf_scores)"
   ],
   "id": "a49a6e0ba52bf644",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aggression   animals      cats    clean  contentment      dark  excellent  \\\n",
      "0     0.00000  0.000000  0.208755  0.00000      0.00000  0.000000   0.000000   \n",
      "1     0.00000  0.000000  0.252931  0.00000      0.00000  0.000000   0.000000   \n",
      "2     0.00000  0.572129  0.284415  0.00000      0.00000  0.000000   0.000000   \n",
      "3     0.00000  0.000000  0.252931  0.00000      0.00000  0.000000   0.684115   \n",
      "4     0.00000  0.572129  0.284415  0.76927      0.00000  0.000000   0.000000   \n",
      "5     0.00000  0.000000  0.218645  0.00000      0.59138  0.000000   0.000000   \n",
      "6     0.59138  0.000000  0.218645  0.00000      0.00000  0.000000   0.000000   \n",
      "7     0.00000  0.000000  0.208755  0.00000      0.00000  0.000000   0.000000   \n",
      "8     0.00000  0.000000  0.252931  0.00000      0.00000  0.684115   0.000000   \n",
      "9     0.00000  0.572129  0.284415  0.00000      0.00000  0.000000   0.000000   \n",
      "\n",
      "      hiss   hunters  independent  ...     pets  playful  popular     purr  \\\n",
      "0  0.00000  0.000000      0.00000  ...  0.56463  0.00000  0.56463  0.00000   \n",
      "1  0.00000  0.000000      0.00000  ...  0.00000  0.00000  0.00000  0.00000   \n",
      "2  0.00000  0.000000      0.76927  ...  0.00000  0.00000  0.00000  0.00000   \n",
      "3  0.00000  0.684115      0.00000  ...  0.00000  0.00000  0.00000  0.00000   \n",
      "4  0.00000  0.000000      0.00000  ...  0.00000  0.00000  0.00000  0.00000   \n",
      "5  0.00000  0.000000      0.00000  ...  0.00000  0.00000  0.00000  0.59138   \n",
      "6  0.59138  0.000000      0.00000  ...  0.00000  0.00000  0.00000  0.00000   \n",
      "7  0.00000  0.000000      0.00000  ...  0.00000  0.00000  0.00000  0.00000   \n",
      "8  0.00000  0.000000      0.00000  ...  0.00000  0.00000  0.00000  0.00000   \n",
      "9  0.00000  0.000000      0.00000  ...  0.00000  0.76927  0.00000  0.00000   \n",
      "\n",
      "        see    sense      show    smell   strong    world  \n",
      "0  0.000000  0.00000  0.000000  0.00000  0.00000  0.56463  \n",
      "1  0.000000  0.00000  0.000000  0.00000  0.00000  0.00000  \n",
      "2  0.000000  0.00000  0.000000  0.00000  0.00000  0.00000  \n",
      "3  0.000000  0.00000  0.000000  0.00000  0.00000  0.00000  \n",
      "4  0.000000  0.00000  0.000000  0.00000  0.00000  0.00000  \n",
      "5  0.000000  0.00000  0.502727  0.00000  0.00000  0.00000  \n",
      "6  0.000000  0.00000  0.502727  0.00000  0.00000  0.00000  \n",
      "7  0.000000  0.56463  0.000000  0.56463  0.56463  0.00000  \n",
      "8  0.684115  0.00000  0.000000  0.00000  0.00000  0.00000  \n",
      "9  0.000000  0.00000  0.000000  0.00000  0.00000  0.00000  \n",
      "\n",
      "[10 rows x 22 columns]\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:36:56.883429Z",
     "start_time": "2024-10-13T19:36:56.881273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.util import bigrams\n",
    "from collections import Counter\n",
    "import math\n",
    "texts"
   ],
   "id": "40d60b00b36f0891",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cats are the most popular pets in the world',\n",
       " 'Cats have nine lives',\n",
       " 'Cats are very independent animals',\n",
       " 'Cats are excellent hunters',\n",
       " 'Cats are very clean animals',\n",
       " 'Cats can purr to show contentment',\n",
       " 'Cats can hiss to show aggression',\n",
       " 'Cats have a very strong sense of smell',\n",
       " 'Cats can see in the dark',\n",
       " 'Cats are very playful animals']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:48:15.455896Z",
     "start_time": "2024-10-13T19:48:15.452224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bigrams_list = [list(bigrams(text.split())) for text in texts]\n",
    "bigram_counts = Counter(bigram for bigrams in bigrams_list for bigram in bigrams)\n",
    "unigram_counts = Counter(word for words in texts for word in words.split())\n",
    "print(bigrams_list)\n",
    "print(bigram_counts)\n",
    "print(unigram_counts)"
   ],
   "id": "d820946b46817f09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Cats', 'are'), ('are', 'the'), ('the', 'most'), ('most', 'popular'), ('popular', 'pets'), ('pets', 'in'), ('in', 'the'), ('the', 'world')], [('Cats', 'have'), ('have', 'nine'), ('nine', 'lives')], [('Cats', 'are'), ('are', 'very'), ('very', 'independent'), ('independent', 'animals')], [('Cats', 'are'), ('are', 'excellent'), ('excellent', 'hunters')], [('Cats', 'are'), ('are', 'very'), ('very', 'clean'), ('clean', 'animals')], [('Cats', 'can'), ('can', 'purr'), ('purr', 'to'), ('to', 'show'), ('show', 'contentment')], [('Cats', 'can'), ('can', 'hiss'), ('hiss', 'to'), ('to', 'show'), ('show', 'aggression')], [('Cats', 'have'), ('have', 'a'), ('a', 'very'), ('very', 'strong'), ('strong', 'sense'), ('sense', 'of'), ('of', 'smell')], [('Cats', 'can'), ('can', 'see'), ('see', 'in'), ('in', 'the'), ('the', 'dark')], [('Cats', 'are'), ('are', 'very'), ('very', 'playful'), ('playful', 'animals')]]\n",
      "Counter({('Cats', 'are'): 5, ('are', 'very'): 3, ('Cats', 'can'): 3, ('in', 'the'): 2, ('Cats', 'have'): 2, ('to', 'show'): 2, ('are', 'the'): 1, ('the', 'most'): 1, ('most', 'popular'): 1, ('popular', 'pets'): 1, ('pets', 'in'): 1, ('the', 'world'): 1, ('have', 'nine'): 1, ('nine', 'lives'): 1, ('very', 'independent'): 1, ('independent', 'animals'): 1, ('are', 'excellent'): 1, ('excellent', 'hunters'): 1, ('very', 'clean'): 1, ('clean', 'animals'): 1, ('can', 'purr'): 1, ('purr', 'to'): 1, ('show', 'contentment'): 1, ('can', 'hiss'): 1, ('hiss', 'to'): 1, ('show', 'aggression'): 1, ('have', 'a'): 1, ('a', 'very'): 1, ('very', 'strong'): 1, ('strong', 'sense'): 1, ('sense', 'of'): 1, ('of', 'smell'): 1, ('can', 'see'): 1, ('see', 'in'): 1, ('the', 'dark'): 1, ('very', 'playful'): 1, ('playful', 'animals'): 1})\n",
      "Counter({'Cats': 10, 'are': 5, 'very': 4, 'the': 3, 'animals': 3, 'can': 3, 'in': 2, 'have': 2, 'to': 2, 'show': 2, 'most': 1, 'popular': 1, 'pets': 1, 'world': 1, 'nine': 1, 'lives': 1, 'independent': 1, 'excellent': 1, 'hunters': 1, 'clean': 1, 'purr': 1, 'contentment': 1, 'hiss': 1, 'aggression': 1, 'a': 1, 'strong': 1, 'sense': 1, 'of': 1, 'smell': 1, 'see': 1, 'dark': 1, 'playful': 1})\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:52:13.353206Z",
     "start_time": "2024-10-13T19:52:13.350595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_pmi(bigram, unigram_counts):\n",
    "    p_bigram = bigram_counts[bigram] / len(bigrams_list)\n",
    "    p_word1 = unigram_counts[bigram[0]] / len(bigrams_list)\n",
    "    p_word2 = unigram_counts[bigram[1]] / len(bigrams_list)\n",
    "    return math.log2(p_bigram / (p_word1 * p_word2))\n",
    "\n",
    "\n",
    "pmi_scores = [(bigram, calculate_pmi(bigram, unigram_counts)) for bigram in bigram_counts]\n",
    "pmi_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"Top 5 PMI Scores:\")\n",
    "print(pmi_scores[:5])"
   ],
   "id": "31e06d177e7ecff8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 PMI Scores:\n",
      "[(('most', 'popular'), 3.321928094887362), (('popular', 'pets'), 3.321928094887362), (('nine', 'lives'), 3.321928094887362), (('excellent', 'hunters'), 3.321928094887362), (('strong', 'sense'), 3.321928094887362)]\n"
     ]
    }
   ],
   "execution_count": 112
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
